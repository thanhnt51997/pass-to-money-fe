# Evaluate Single Answer

API nội bộ (Job) để đánh giá một câu trả lời duy nhất bằng AI.

## Mô tả
Khi ứng viên submit câu trả lời cho câu hỏi dạng essay/theoretical/coding, hệ thống sẽ tự động dispatch một background job để đánh giá câu trả lời đó bằng AI.

## Luồng xử lý

### 1. Trigger
- Được kích hoạt tự động khi ứng viên submit answer cho câu hỏi dạng: `theoretical`, `essay`, `coding`
- Job: `EvaluateSingleAnswerJob`

### 2. Input
- `interview_id`: ID của phiên phỏng vấn
- `question_id`: ID của câu hỏi cần đánh giá

### 3. Process
1. Load interview session và câu hỏi
2. Xây dựng prompt AI qua `AiPromptBuilder`
3. Gọi AI Client để đánh giá
4. Parse kết quả AI (score, strengths, weaknesses, comment)
5. Clamp score trong khoảng 0-10
6. Lưu kết quả đánh giá vào `interview_answers` table

### 4. Output (Saved to DB)
```json
{
  "status": "evaluated",
  "score": 8,
  "strengths": [
    "Clear understanding of the concept",
    "Good practical examples"
  ],
  "weaknesses": [
    "Missing edge case handling",
    "Could explain performance implications"
  ],
  "comment": "Solid answer with room for improvement on advanced topics",
  "evaluated_at": "2026-01-19 10:30:00"
}
```

## Business Rules
- AI client phải được inject (có thể swap với FakeAiClient cho testing)
- Xử lý malformed AI response gracefully (fallback score = 0)
- Score luôn được clamp trong khoảng [0, 10]
- Nếu evaluation fail, không làm crash toàn bộ interview session

## Files liên quan
- `App\Infrastructure\Evaluation\Jobs\EvaluateSingleAnswerJob`
- `App\Domain\Evaluation\Services\EvaluationService`
- `App\Domain\Evaluation\Services\AiPromptBuilder`
- `App\Domain\Evaluation\Services\AiClient`
- `App\Domain\Evaluation\Models\QuestionEvaluation`
